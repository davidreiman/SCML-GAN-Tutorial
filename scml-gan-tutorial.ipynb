{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network (GAN) Tutorial in PyTorch\n",
    "---\n",
    "### By David Reiman (dreiman@ucsc.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./docs/images/GAN.png\"><br>\n",
    "<div style=\"text-align: right\">(Image credit: <a href=\"https://medium.freecodecamp.org/an-intuitive-introduction-to-generative-adversarial-networks-gans-7a2264a81394\">Thalles Silva</a>)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some imports first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import math\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the matplotlib style to something a little prettier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify our generator network architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./docs/images/dcgan-generator.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(100, 8*8*32)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=32, \n",
    "                out_channels=32, \n",
    "                kernel_size=3, \n",
    "                stride=1, \n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=32, \n",
    "                out_channels=16, \n",
    "                kernel_size=3, \n",
    "                stride=1, \n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=16, \n",
    "                out_channels=8, \n",
    "                kernel_size=3, \n",
    "                stride=1, \n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Conv2d(\n",
    "                in_channels=8, \n",
    "                out_channels=3, \n",
    "                kernel_size=3, \n",
    "                stride=1, \n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = self.linear(z)\n",
    "        z = z.view(z.shape[0], 32, 8, 8)\n",
    "        z = self.conv(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our discriminator network architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=3, \n",
    "                out_channels=32, \n",
    "                kernel_size=3, \n",
    "                stride=2, \n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=32, \n",
    "                out_channels=64, \n",
    "                kernel_size=3, \n",
    "                stride=2, \n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=64, \n",
    "                out_channels=128, \n",
    "                kernel_size=3, \n",
    "                stride=2, \n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=128, \n",
    "                out_channels=256, \n",
    "                kernel_size=3, \n",
    "                stride=2, \n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(4*4*256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our filepaths and a few hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = './data'\n",
    "save_path = './images'\n",
    "epochs = 200\n",
    "batch_size = 64\n",
    "lr = 0.0002\n",
    "sample_interval = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the save path doesn't exist, we'll create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define data preprocessing steps for data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize([64, 64]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define image folder dataset with path and transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(\n",
    "    root=data_path,\n",
    "    transform=data_transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data loader from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_loader = data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=cuda,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll make our generator/discriminator instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And define our loss function: binary cross entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adversarial_loss = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If PyTorch found a GPU, we'll store our model parameters on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll define our optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the Tensor function as the cuda/non-cuda version based on if PyTorch found a GPU or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the ground truth \"labels\" for the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ones = Variable(Tensor(batch_size, 1).fill_(1.0), requires_grad=False)\n",
    "zeros = Variable(Tensor(batch_size, 1).fill_(0.0), requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix a latent vector to see how the outputs transform for a constant latent input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_fixed = Variable(Tensor(np.random.normal(0, 1, [batch_size, 100])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we setup the training loop and get to learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "    for i, (images, _) in tqdm(enumerate(data_loader), total=len(data_loader), leave=False):\n",
    "\n",
    "        # Create a latent input for generator — this is a draw from a spherical Gaussian\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, [batch_size, 100])))\n",
    "        \n",
    "        # Make a batch of fake images from latent input\n",
    "        fake_images = generator(z)\n",
    "        \n",
    "        # Get a batch of real images from the data loader\n",
    "        real_images = Variable(images.type(Tensor))\n",
    "        \n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        \n",
    "        # Clear gradients from previous update steps\n",
    "        opt_d.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to differentiate real vs. generated samples\n",
    "        real_loss = adversarial_loss(discriminator(real_images), ones)\n",
    "        fake_loss = adversarial_loss(discriminator(fake_images.detach()), zeros)\n",
    "        d_loss = (real_loss + fake_loss) / 2.\n",
    "        \n",
    "        # Backpropagate the gradient information and make an update step on d\n",
    "        d_loss.backward()\n",
    "        opt_d.step()\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "        \n",
    "        # Clear gradients from previous update steps\n",
    "        opt_g.zero_grad()\n",
    "\n",
    "        # Train the generator to maximize the discriminator's probability estimates on fake images\n",
    "        g_loss = adversarial_loss(discriminator(fake_images), ones)\n",
    "\n",
    "        # Backpropagate the gradient information and make an update step on g\n",
    "        g_loss.backward()\n",
    "        opt_g.step()\n",
    "        \n",
    "        # Save a generated sample every sample_interval batches\n",
    "        batches_done = epoch * len(data_loader) + i\n",
    "        if batches_done % sample_interval == 0:\n",
    "            test_images = generator(z_fixed)\n",
    "            filename = os.path.join(save_path, '%d.png' % batches_done)\n",
    "            save_image(test_images.data[:25], filename, nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All done training. Let's check the last sample generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./samples/31000.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also look at the evolution of the generator's outputs for 25 fixed latent inputs over the course of training for 200 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./samples/animate.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References \n",
    "The majority of this code was adapted from Erik Linder-Norén's excellent repository of <a href=\"https://github.com/eriklindernoren/PyTorch-GAN\">GAN implementations in PyTorch</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
